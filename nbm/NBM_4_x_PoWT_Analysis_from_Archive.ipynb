{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzF4NfOcHz2VXf1azfEcev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-wessler/wr-stid-notebooks/blob/main/nbm/NBM_4_x_PoWT_Analysis_from_Archive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NBM 4.x PoWT Analysis from Archive\n",
        "\n",
        "**Author:** Michael Wessler<br>\n",
        "**Organization:** Western Region STID  \n",
        "**Last Updated:** June 2025\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This Jupyter notebook provides a probabilistic analysis and verification of the National Blend of Models (NBM) 4.x Probability of Weather Type (PoWT).  \n",
        "\n",
        "It loads and processes a large, lightly quality-controlled dataset of NBM PoWT forecasts and corresponding observed weather polled from ASOS/AWOS stations available through Synoptic Data's API, producing a range of plots including diagnostics, skill metrics, and reliability.\n",
        "\n",
        "This notebook is intended to support research, verification, and operational review of NBM PoWT guidance.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MpBpo69G5BVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Installs and Imports: Run this cell once to initialize notebook\n",
        "%%capture\n",
        "\n",
        "!pip install gdown\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "import requests\n",
        "import gdown\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.patches import Patch\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "from ipywidgets import Tab, Output\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "def optimize_df(df):\n",
        "    \"\"\"\n",
        "    Rounds all float columns in a DataFrame to three decimal places,\n",
        "    leaving integer columns unchanged.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        The input DataFrame.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        A copy of the DataFrame with float columns rounded to three decimals.\n",
        "    \"\"\"\n",
        "    updated_df = df.copy()  # Avoid mutating the original DataFrame\n",
        "\n",
        "    for col in updated_df.columns:\n",
        "        col_dtype = updated_df[col].dtype\n",
        "\n",
        "        if pd.api.types.is_float_dtype(col_dtype):\n",
        "            updated_df[col] = updated_df[col].round(3)\n",
        "        # Integers and non-numeric columns are left unchanged\n",
        "\n",
        "    return updated_df\n",
        "\n",
        "def wet_bulb_temperature_stull(T, RH):\n",
        "    \"\"\"\n",
        "    Calculate the wet bulb temperature using the Stull (2011) formula.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    T : array-like or float\n",
        "        Air temperature in degrees Celsius.\n",
        "    RH : array-like or float\n",
        "        Relative humidity in percent (0-100).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray or float\n",
        "        Wet bulb temperature in degrees Celsius.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    Reference: Stull, R. (2011). Wet-Bulb Temperature from Relative Humidity and Air Temperature.\n",
        "    Journal of Applied Meteorology and Climatology, 50, 2267–2269.\n",
        "    \"\"\"\n",
        "    T = np.asarray(T)\n",
        "    RH = np.asarray(RH)\n",
        "    tw = (\n",
        "        T * np.arctan(0.151977 * np.sqrt(RH + 8.313659)) +\n",
        "        np.arctan(T + RH) -\n",
        "        np.arctan(RH - 1.676331) +\n",
        "        0.00391838 * RH ** 1.5 * np.arctan(0.023101 * RH) -\n",
        "        4.686035\n",
        "    )\n",
        "    return tw\n",
        "\n",
        "def clamp_to_cool_season(date_obj):\n",
        "    # Only allow Oct 1 - May 31 (inclusive) for each year\n",
        "    year = date_obj.year\n",
        "    cool_season_start = datetime.date(year, 10, 1)\n",
        "    cool_season_end = datetime.date(year + 1, 5, 31)\n",
        "    if date_obj < cool_season_start:\n",
        "        return cool_season_start\n",
        "    elif date_obj > cool_season_end:\n",
        "        return cool_season_end\n",
        "    else:\n",
        "        return date_obj\n",
        "\n",
        "def clamp_date(date_str, default, min_date, max_date):\n",
        "    try:\n",
        "        d = datetime.datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
        "        # Clamp to dataset bounds\n",
        "        if d < min_date:\n",
        "            d = min_date\n",
        "        elif d > max_date:\n",
        "            d = max_date\n",
        "        # Clamp to cool season\n",
        "        d = clamp_to_cool_season(d)\n",
        "        # Clamp again to dataset bounds in case cool season adjustment pushed out-of-bounds\n",
        "        if d < min_date:\n",
        "            d = min_date\n",
        "        elif d > max_date:\n",
        "            d = max_date\n",
        "        return d.strftime(\"%Y-%m-%d\")\n",
        "    except Exception:\n",
        "        return default"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WFK5dwq16Jdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title NBM PoWT Configuration: User Selectable Options\n",
        "# @markdown ---\n",
        "# @markdown **Instructions:**\n",
        "# @markdown Please use the form below to configure your analysis.\n",
        "# @markdown\n",
        "\n",
        "\n",
        "# @markdown **Dataset file:**\n",
        "# @markdown The default dataset is pre-loaded. You may specify a different file if needed.\n",
        "# Fetch the databse file from Drive\n",
        "file_id = \"1hTh9kfnVRVjjN_McE-eY9BIlsbuLbDQv\"  # @param {type:\"string\"}\n",
        "database_file = \"/content/NBM_PoWT_Dataset_20230120_20250430.parquet.gzip\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **County Warning Area (CWA):**\n",
        "# @markdown Available CWAs:\n",
        "# @markdown BOI, BYZ, EKA, FGZ, GGW, HNX, LKN, LOX, MFR, MSO, MTR, OTX, PDT, PIH, PQR, PSR, REV, SEW, SGX, SLC, STO, TFX, TWC, VEF\n",
        "# @markdown Enter a comma-separated list (e.g., `MSO,BOI,PIH`). Leave blank or enter \"None\" to use all CWAs.\n",
        "cwa_selection = \"SEW,PQR\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown **Forecast Hour (FHR):**\n",
        "# @markdown Available FHRs:\n",
        "# @markdown 24, 36, 48, 72, 120, 168\n",
        "# @markdown Enter a comma-separated list (e.g., `24,72,168`). Leave blank or enter \"None\" to use all FHRs.\n",
        "fhr_selection = \"24,48,72\"    # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown **Date Range (required):**\n",
        "# @markdown Enter your desired date range in `YYYY-MM-DD` format.\n",
        "# @markdown - **First available date:** 2023-01-20\n",
        "# @markdown - **Last available date:** 2025-04-30\n",
        "# @markdown - **Data is available for the cool season only:** October 1 to May 31, where available within the dataset.\n",
        "# @markdown - Dates outside the available data range or outside the cool season will automatically be adjusted to the nearest valid date.\n",
        "start_date_selection = \"2023-01-20\"  # @param {type:\"string\"}\n",
        "end_date_selection = \"2025-04-30\"    # @param {type:\"string\"}\n",
        "\n",
        "# Define valid range\n",
        "first_available_date = datetime.date(2023, 1, 20)\n",
        "last_available_date = datetime.date(2025, 4, 30)\n",
        "\n",
        "start_date_selection = clamp_date(\n",
        "    start_date_selection,\n",
        "    first_available_date.strftime(\"%Y-%m-%d\"),\n",
        "    first_available_date,\n",
        "    last_available_date\n",
        ")\n",
        "end_date_selection = clamp_date(\n",
        "    end_date_selection,\n",
        "    last_available_date.strftime(\"%Y-%m-%d\"),\n",
        "    first_available_date,\n",
        "    last_available_date\n",
        ")\n",
        "\n",
        "def parse_selection(selection):\n",
        "    if not selection or selection.strip().lower() == \"none\":\n",
        "        return None\n",
        "    return [item.strip() for item in selection.split(\",\") if item.strip()]\n",
        "\n",
        "cwa_selection = parse_selection(cwa_selection)\n",
        "fhr_selection = parse_selection(fhr_selection)\n",
        "if fhr_selection is not None:\n",
        "    fhr_selection = [int(fhr) for fhr in fhr_selection]\n",
        "\n",
        "gdown_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "if os.path.exists(database_file):\n",
        "    print(f\"File already exists: {database_file}\")\n",
        "else:\n",
        "    print(f\"Downloading to {database_file} ...\")\n",
        "    gdown.download(gdown_url, output=database_file, quiet=False)\n",
        "\n",
        "print(\"Database file:\", database_file)\n",
        "\n",
        "df = optimize_df(pd.read_parquet(database_file))\n",
        "gc.collect()\n",
        "\n",
        "# Ensure the timestamp index level is in datetime format\n",
        "df.index = df.index.set_levels(\n",
        "    pd.to_datetime(df.index.levels[0]), level='timestamp'\n",
        ")\n",
        "\n",
        "df.sort_index(inplace=True)\n",
        "\n",
        "# --- Date range filtering ---\n",
        "if start_date_selection or end_date_selection:\n",
        "    ts = df.index.get_level_values('timestamp')\n",
        "    mask = pd.Series(True, index=df.index)\n",
        "    if start_date_selection:\n",
        "        mask &= (ts >= pd.to_datetime(start_date_selection))\n",
        "    if end_date_selection:\n",
        "        mask &= (ts <= pd.to_datetime(end_date_selection))\n",
        "    df = df[mask]\n",
        "    print(f\"Filtered by date range: {start_date_selection} to {end_date_selection}\")\n",
        "else:\n",
        "    print(\"No date range selected. Using all dates.\")\n",
        "\n",
        "# Filter by CWA (County Warning Area)\n",
        "if cwa_selection:\n",
        "    print(f\"Selected CWAs: {cwa_selection}\")\n",
        "    cwa_mask = df.index.get_level_values('cwa').isin(cwa_selection)\n",
        "    df = df[cwa_mask]\n",
        "else:\n",
        "    print(\"No CWAs selected. Using all stations.\")\n",
        "\n",
        "# Filter by FHR (forecast hour)\n",
        "if fhr_selection:\n",
        "    print(f\"Selected FHRs: {fhr_selection}\")\n",
        "    fhr_mask = df.index.get_level_values(\"fhr\").isin(fhr_selection)\n",
        "    df = df[fhr_mask]\n",
        "else:\n",
        "    print(\"No FHR selected. Using all FHRs.\")\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "start_date = df.index.get_level_values('timestamp').min().strftime('%Y-%m-%d')\n",
        "end_date = df.index.get_level_values('timestamp').max().strftime('%Y-%m-%d')\n",
        "\n",
        "df['snowlvl_agl'] = df['snowlvl'] - df['elevation']\n",
        "\n",
        "initial_size = df.shape[0]\n",
        "print(f\"\\nInitial row count: {initial_size}\")\n",
        "\n",
        "mask_qc1 = (\n",
        "    (df['Tw'] > 36) &\n",
        "    (df[['SN', 'ZR', 'PL', 'UP']].any(axis=1))\n",
        ")\n",
        "n_removed_qc1 = mask_qc1.sum()\n",
        "pct_removed_qc1 = 100 * n_removed_qc1 / initial_size\n",
        "print(f\"QC Step 1: Remove ZR/PL/SN/UP when Tw > 36°F\")\n",
        "print(f\"  Rows removed: {n_removed_qc1} ({pct_removed_qc1:.2f}%)\")\n",
        "df = df.loc[~mask_qc1].copy()\n",
        "size_after_qc1 = df.shape[0]\n",
        "\n",
        "mask_qc2 = (df['Tw'] < 28) & (df['RA'] == True)\n",
        "n_removed_qc2 = mask_qc2.sum()\n",
        "pct_removed_qc2 = 100 * n_removed_qc2 / initial_size\n",
        "print(f\"QC Step 2: Remove RA when Tw < 28°F\")\n",
        "print(f\"  Rows removed: {n_removed_qc2} ({pct_removed_qc2:.2f}%)\")\n",
        "df = df.loc[~mask_qc2].copy()\n",
        "size_after_qc2 = df.shape[0]\n",
        "\n",
        "print(f\"Row count after QC Step 1: {size_after_qc1} ({100*size_after_qc1/initial_size:.2f}% of initial)\")\n",
        "print(f\"Row count after QC Step 2: {size_after_qc2} ({100*size_after_qc2/initial_size:.2f}% of initial)\")\n",
        "\n",
        "tempqc_mae_threshold = 25\n",
        "df.loc[:, 'abs_error'] = np.abs(df['FXT'] - df['T'])\n",
        "mae = df['abs_error'].mean()\n",
        "print(f\"Mean Absolute Error (MAE) between FXT and T: {mae:.3f}\")\n",
        "\n",
        "n_before = df.shape[0]\n",
        "df = df.loc[df['abs_error'] <= tempqc_mae_threshold].copy()\n",
        "n_after = df.shape[0]\n",
        "n_removed = n_before - n_after\n",
        "pct_removed = 100 * n_removed / n_before\n",
        "print(f\"Rows removed (abs_error > {tempqc_mae_threshold}): {n_removed} ({pct_removed:.2f}%)\")\n",
        "print(f\"Remaining rows: {n_after}\")\n",
        "\n",
        "df = df.drop(columns=['abs_error'])\n",
        "\n",
        "df.loc[:, ['PRA', 'PSN', 'PZR', 'PPL']] = df.loc[:, ['PRA', 'PSN', 'PZR', 'PPL']] / 100\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "combo_output = Output()\n",
        "with combo_output:\n",
        "    obs_types = ['RA', 'SN', 'ZR', 'PL', 'UP']\n",
        "    fcst_types = ['PRA', 'PSN', 'PZR', 'PPL']\n",
        "    fcst_thresh = 0.15\n",
        "    combo_colors = ['#228B22', '#1E3A8A', '#008B8B', '#800080', '#C62828']  # green, blue, teal, purple, red\n",
        "\n",
        "    # Helper: get color for each combo label\n",
        "    def combo_color(label, labels=obs_types):\n",
        "        # Use the color of the first type in the label\n",
        "        for i, t in enumerate(labels):\n",
        "            if t in label.split(\",\"):\n",
        "                return combo_colors[i]\n",
        "        return \"#999999\"\n",
        "\n",
        "    # --- Observed Combination Histogram ---\n",
        "    obs_combo_counts = {}\n",
        "    for i in range(1, 5):\n",
        "        for combo in itertools.combinations(obs_types, i):\n",
        "            combo_series = df[list(combo)].all(axis=1)\n",
        "            obs_combo_counts[','.join(combo)] = combo_series.sum()\n",
        "    filtered_obs_combo_counts = {k: v for k, v in obs_combo_counts.items() if v >= 1}\n",
        "    obs_total = sum(filtered_obs_combo_counts.values())\n",
        "    obs_combo_labels = list(filtered_obs_combo_counts.keys())\n",
        "    obs_combo_values = list(filtered_obs_combo_counts.values())\n",
        "    obs_combo_barcolors = [combo_color(l, obs_types) for l in obs_combo_labels]\n",
        "\n",
        "    # --- Forecast Combination Histogram ---\n",
        "    fcst_combo_counts = {}\n",
        "    fcst_bool = df[fcst_types] > fcst_thresh\n",
        "    for i in range(1, 5):\n",
        "        for combo in itertools.combinations(fcst_types, i):\n",
        "            combo_bool = fcst_bool[list(combo)].all(axis=1)\n",
        "            fcst_combo_counts[','.join(combo)] = combo_bool.sum()\n",
        "    filtered_fcst_combo_counts = {k: v for k, v in fcst_combo_counts.items() if v >= 1}\n",
        "    fcst_total = sum(filtered_fcst_combo_counts.values())\n",
        "    fcst_combo_labels = list(filtered_fcst_combo_counts.keys())\n",
        "    fcst_combo_values = list(filtered_fcst_combo_counts.values())\n",
        "    fcst_combo_barcolors = [combo_color(l, fcst_types) for l in fcst_combo_labels]\n",
        "\n",
        "    # --- Plot stacked (top: observed, bottom: forecast) ---\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=False)\n",
        "\n",
        "    # Observed\n",
        "    obs_x = range(len(obs_combo_labels))\n",
        "    bars = axes[0].bar(obs_x, obs_combo_values)#, color=obs_combo_barcolors)\n",
        "    axes[0].set_title(\"Observed Weather Condition Combinations\", fontsize=15)\n",
        "    axes[0].set_xlabel('Condition Combinations', fontsize=14)\n",
        "    axes[0].set_ylabel('Frequency (symlog-y)', fontsize=14)\n",
        "    axes[0].set_yscale('symlog', linthresh=1)\n",
        "    axes[0].set_xticks(obs_x)\n",
        "    axes[0].set_xticklabels(obs_combo_labels, rotation=45, ha='right', fontsize=13)\n",
        "    max_y = max(obs_combo_values) if obs_combo_values else 1\n",
        "    axes[0].set_ylim(top=max_y * 5)\n",
        "    axes[0].set_yticks(axes[0].get_yticks())\n",
        "    axes[0].tick_params(axis='y', labelsize=13)\n",
        "    threshold_y = max_y * 0.0001\n",
        "    for idx, (bar, value) in enumerate(zip(bars, obs_combo_values)):\n",
        "        perc = (value / obs_total) * 100 if obs_total else 0\n",
        "        if value <= threshold_y:\n",
        "            axes[0].text(\n",
        "                bar.get_x() + bar.get_width() / 2, value, f\"  {perc:.4f}% \\n({value:d}) \",\n",
        "                ha='center', va='bottom', fontsize=11, color='black', weight='bold', rotation=45,\n",
        "            )\n",
        "        else:\n",
        "            axes[0].text(\n",
        "                bar.get_x() + bar.get_width() / 2, value, f\" {perc:.2f}% \\n({value:d}) \",\n",
        "                ha='center', va='top', fontsize=11, color='white', weight='bold', rotation=45\n",
        "            )\n",
        "\n",
        "    # Forecast\n",
        "    fcst_x = range(len(fcst_combo_labels))\n",
        "    bars2 = axes[1].bar(fcst_x, fcst_combo_values)#, color=fcst_combo_barcolors)\n",
        "    axes[1].set_title(\"Forecast Weather Condition Combinations\\n(Forecast Probability > 15%)\", fontsize=15)\n",
        "    axes[1].set_xlabel('Forecast Condition Combinations', fontsize=14)\n",
        "    axes[1].set_ylabel('Frequency (symlog-y)', fontsize=14)\n",
        "    axes[1].set_yscale('symlog', linthresh=1)\n",
        "    axes[1].set_xticks(fcst_x)\n",
        "    axes[1].set_xticklabels(fcst_combo_labels, rotation=45, ha='right', fontsize=13)\n",
        "    max_y2 = max(fcst_combo_values) if fcst_combo_values else 1\n",
        "    axes[1].set_ylim(top=max_y2 * 5)\n",
        "    axes[1].set_yticks(axes[1].get_yticks())\n",
        "    axes[1].tick_params(axis='y', labelsize=13)\n",
        "    threshold_y2 = max_y2 * 0.0001\n",
        "    for idx, (bar, value) in enumerate(zip(bars2, fcst_combo_values)):\n",
        "        perc = (value / fcst_total) * 100 if fcst_total else 0\n",
        "        if value <= threshold_y2:\n",
        "            axes[1].text(\n",
        "                bar.get_x() + bar.get_width() / 2, value, f\"  {perc:.4f}% \\n({value:d}) \",\n",
        "                ha='center', va='bottom', fontsize=11, color='black', weight='bold', rotation=45,\n",
        "            )\n",
        "        else:\n",
        "            axes[1].text(\n",
        "                bar.get_x() + bar.get_width() / 2, value, f\" {perc:.2f}% \\n({value:d}) \",\n",
        "                ha='center', va='top', fontsize=11, color='white', weight='bold', rotation=45\n",
        "            )\n",
        "\n",
        "    # Title & info\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df)\n",
        "    plot_title = (\n",
        "        f\"Observed & Forecast Weather Condition Combinations\\n\"\n",
        "        f\"{start_date} to {end_date} | CWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "    fig.suptitle(plot_title, fontsize=17)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- 2. 2x2 Histogram Panel Plot ---\n",
        "hist2x2_output = Output()\n",
        "def plot_weather_histogram_snowlvl_or_fxtw_prob_fxtw_2x2(df):\n",
        "    weather_cols = ['RA', 'SN', 'ZR', 'PL', 'UP']\n",
        "    prob_cols = ['PSN', 'PZR', 'PPL']\n",
        "\n",
        "    mask_00 = ((df['snowlvl_agl'] > 800) | (df['FXTw'] > 36)) & df[weather_cols].any(axis=1)\n",
        "    df_00 = df.loc[mask_00]\n",
        "    counts_00 = df_00[weather_cols].sum()\n",
        "    counts_00 = counts_00[counts_00 > 0]\n",
        "    total_00 = len(df_00)\n",
        "\n",
        "    mask_prob = (df[prob_cols] > 0.15).any(axis=1)\n",
        "    mask_01 = mask_00 & mask_prob\n",
        "    df_01 = df.loc[mask_01]\n",
        "    counts_01 = df_01[weather_cols].sum()\n",
        "    counts_01 = counts_01[counts_01 > 0]\n",
        "    total_01 = len(df_01)\n",
        "\n",
        "    mask_10 = (df['snowlvl_agl'] > 800) & (df['FXTw'] > 36) & df[weather_cols].any(axis=1)\n",
        "    df_10 = df.loc[mask_10]\n",
        "    counts_10 = df_10[weather_cols].sum()\n",
        "    counts_10 = counts_10[counts_10 > 0]\n",
        "    total_10 = len(df_10)\n",
        "\n",
        "    mask_11 = mask_10 & mask_prob\n",
        "    df_11 = df.loc[mask_11]\n",
        "    counts_11 = df_11[weather_cols].sum()\n",
        "    counts_11 = counts_11[counts_11 > 0]\n",
        "    total_11 = len(df_11)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12), sharey=True)\n",
        "    panels = [\n",
        "        (axes[0,0], counts_00, total_00, \"Snow Level > 800 AGL OR FXTw > 36\\n(≥1 weather observed)\"),\n",
        "        (axes[0,1], counts_01, total_01, \"Snow > 800 OR FXTw > 36\\nand ≥1(PSN/PZR/PPL) > 15%\"),\n",
        "        (axes[1,0], counts_10, total_10, \"Snow > 800 AND FXTw > 36\\n(≥1 weather observed)\"),\n",
        "        (axes[1,1], counts_11, total_11, \"Snow > 800 AND FXTw > 36\\nand ≥1(PSN/PZR/PPL) > 15%\")\n",
        "    ]\n",
        "    for ax, counts, total, title in panels:\n",
        "        if not counts.empty:\n",
        "            bars = ax.bar(counts.index, counts.values, color='cornflowerblue', edgecolor='black')\n",
        "            for bar, val in zip(bars, counts.values):\n",
        "                pct = val / total * 100 if total else 0\n",
        "                ax.text(bar.get_x() + bar.get_width()/2, val,\n",
        "                        f\"{pct:.2f}% (n={val})\",\n",
        "                        ha=\"center\", va=\"bottom\", fontsize=11)\n",
        "            ax.set_title(title)\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, \"No data for this panel\", ha='center', va='center', transform=ax.transAxes)\n",
        "            ax.set_title(f\"No Data\\n({title})\")\n",
        "            ax.axis('off')\n",
        "        ax.set_xlabel(\"Weather Condition\")\n",
        "        ax.set_yscale(\"log\")\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    axes[0,0].set_ylabel(\"Frequency (log)\")\n",
        "    axes[1,0].set_ylabel(\"Frequency (log)\")\n",
        "\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    case_count = len(df)\n",
        "    plot_title = (\n",
        "        f\"Frequency of Observed Weather Conditions\\n\"\n",
        "        f\"{start_date} to {end_date} | CWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "    fig.suptitle(plot_title, fontsize=15)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "with hist2x2_output:\n",
        "    plot_weather_histogram_snowlvl_or_fxtw_prob_fxtw_2x2(df)\n",
        "\n",
        "# --- 3. ZR vs UP Events Panelled Histograms ---\n",
        "hist_panel_output = Output()\n",
        "with hist_panel_output:\n",
        "    cols = [\n",
        "        'T', 'FXT', 'RH', 'FXRH',\n",
        "        'Tw', 'FXTw', 'snowlvl_agl', None,\n",
        "        'PRA', 'PSN', 'PZR', 'PPL'\n",
        "    ]\n",
        "    bin_settings = {\n",
        "        'T': np.arange(-60, 60+2, 2),\n",
        "        'FXT': np.arange(-60, 60+2, 2),\n",
        "        'Tw': np.arange(-60, 60+2, 2),\n",
        "        'FXTw': np.arange(-60, 60+2, 2),\n",
        "        'RH': np.arange(0, 100+5, 5),\n",
        "        'FXRH': np.arange(0, 100+5, 5),\n",
        "        'snowlvl_agl': np.arange(-6400, 6000+200, 400),\n",
        "        'PRA': np.arange(0, 1+0.05, 0.05),\n",
        "        'PSN': np.arange(0, 1+0.05, 0.05),\n",
        "        'PZR': np.arange(0, 1+0.05, 0.05),\n",
        "        'PPL': np.arange(0, 1+0.05, 0.05)\n",
        "    }\n",
        "    zr = df[df['ZR'] == True]\n",
        "    zr_up = df[df['UP'] == True]\n",
        "\n",
        "    fig, axes = plt.subplots(3, 4, figsize=(18, 10))\n",
        "    axes = axes.flatten()\n",
        "    for i, col in enumerate(cols):\n",
        "        ax = axes[i]\n",
        "        if col is not None:\n",
        "            bins = bin_settings.get(col, 'auto')\n",
        "            use_kde = not (col in ['PRA', 'PSN', 'PZR', 'PPL'])\n",
        "            h1 = sns.histplot(zr[col].dropna(), bins=bins, kde=use_kde, color='blue', label='ZR', ax=ax, stat='density', alpha=0.4)\n",
        "            h2 = sns.histplot(zr_up[col].dropna(), bins=bins, kde=use_kde, color='orange', label='UP', ax=ax, stat='density', alpha=0.7)\n",
        "            ax.set_title(col)\n",
        "            ax.set_xlabel(col)\n",
        "            ax.set_ylabel('Density')\n",
        "\n",
        "            legend_handles = []\n",
        "            legend_labels = []\n",
        "            for handle, label in zip(*ax.get_legend_handles_labels()):\n",
        "                if label not in legend_labels:\n",
        "                    legend_handles.append(handle)\n",
        "                    legend_labels.append(label)\n",
        "            if col in ['T', 'FXT']:\n",
        "                vline = ax.axvline(32, color='red', linestyle='-', linewidth=1.2, label='32°F')\n",
        "                legend_handles.append(Line2D([0], [0], color='red', linewidth=1.2, linestyle='-', label='32°F'))\n",
        "                legend_labels.append('32°F')\n",
        "            if col in ['Tw', 'FXTw']:\n",
        "                vline = ax.axvline(36, color='red', linestyle='-', linewidth=1.2, label='36°F')\n",
        "                legend_handles.append(Line2D([0], [0], color='red', linewidth=1.2, linestyle='-', label='36°F'))\n",
        "                legend_labels.append('36°F')\n",
        "            if col == 'snowlvl_agl':\n",
        "                vline0 = ax.axvline(0, color='red', linestyle='-', linewidth=1.2, label='0ft')\n",
        "                vline800 = ax.axvline(800, color='red', linestyle='--', linewidth=1.2, label='800ft')\n",
        "                legend_handles.append(Line2D([0], [0], color='red', linewidth=1.2, linestyle='-', label='0ft'))\n",
        "                legend_labels.append('0ft')\n",
        "                legend_handles.append(Line2D([0], [0], color='red', linewidth=1.2, linestyle='--', label='800ft'))\n",
        "                legend_labels.append('800ft')\n",
        "            if col[0] == 'P':\n",
        "                ax.set_yscale('symlog')\n",
        "            ax.legend(handles=legend_handles, labels=legend_labels)\n",
        "        else:\n",
        "            ax.axis('off')\n",
        "\n",
        "    if len(cols) < len(axes):\n",
        "        fig.delaxes(axes[-1])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    case_count = len(df)\n",
        "    plot_title = (f\"Characteristics of Freezing Rain (ZR) and UP Events\\n {start_date} to {end_date} | CWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\")\n",
        "    plt.suptitle(plot_title, fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "prob_hist_output = Output()\n",
        "\n",
        "# --- 4. Forecast Contingency Comparason Histograms ---\n",
        "with prob_hist_output:\n",
        "    font_size = 12\n",
        "    # Drop NaN from relevant columns only (do not drop all rows if other cols have NaN)\n",
        "    pra = df[\"PRA\"].dropna()\n",
        "    psn = df[\"PSN\"].dropna()\n",
        "    ppl = df[\"PPL\"].dropna()\n",
        "    pzr = df[\"PZR\"].dropna()\n",
        "\n",
        "    bins = np.arange(0, 1.1, .1)\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
        "\n",
        "    plt.rc('xtick', labelsize=font_size)\n",
        "    plt.rc('ytick', labelsize=font_size)\n",
        "\n",
        "    axes[0, 0].hist(pra, bins=bins, color='blue', alpha=0.7, log=True)\n",
        "    axes[0, 0].set_title('Histogram of PRA', fontsize=font_size)\n",
        "    axes[0, 0].set_xlabel('PRA', fontsize=font_size)\n",
        "    axes[0, 0].set_ylabel('Log Frequency', fontsize=font_size)\n",
        "    axes[0, 0].grid(True)\n",
        "\n",
        "    axes[0, 1].hist(psn, bins=bins, color='green', alpha=0.7, log=True)\n",
        "    axes[0, 1].set_title('Histogram of PSN', fontsize=font_size)\n",
        "    axes[0, 1].set_xlabel('PSN', fontsize=font_size)\n",
        "    axes[0, 1].set_ylabel('Log Frequency', fontsize=font_size)\n",
        "    axes[0, 1].grid(True)\n",
        "\n",
        "    axes[1, 0].hist(ppl, bins=bins, color='orange', alpha=0.7, log=True)\n",
        "    axes[1, 0].set_title('Histogram of PPL', fontsize=font_size)\n",
        "    axes[1, 0].set_xlabel('PPL', fontsize=font_size)\n",
        "    axes[1, 0].set_ylabel('Log Frequency', fontsize=font_size)\n",
        "    axes[1, 0].grid(True)\n",
        "\n",
        "    axes[1, 1].hist(pzr, bins=bins, color='purple', alpha=0.7, log=True)\n",
        "    axes[1, 1].set_title('Histogram of PZR', fontsize=font_size)\n",
        "    axes[1, 1].set_xlabel('PZR', fontsize=font_size)\n",
        "    axes[1, 1].set_ylabel('Log Frequency', fontsize=font_size)\n",
        "    axes[1, 1].grid(True)\n",
        "\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df)\n",
        "\n",
        "    plot_title = (\n",
        "        f\"Forecast Contingency Comparison\\n\"\n",
        "        f\"{start_date} to {end_date}\\n\"\n",
        "        f\"CWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "\n",
        "    plt.suptitle(plot_title, fontsize=font_size)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "contingency_matrix_output = Output()\n",
        "\n",
        "with contingency_matrix_output:\n",
        "    # ---- USER SETTINGS ----\n",
        "    forecast_cols = ['PRA', 'PSN', 'PZR', 'PPL']\n",
        "    obs_cols = ['RA', 'SN', 'ZR', 'PL', 'UP']\n",
        "    precip_only = True\n",
        "    threshold = 0.15\n",
        "\n",
        "    phenomena_label_map = {\n",
        "        'PRA': 'Rain',\n",
        "        'PSN': 'Snow',\n",
        "        'PZR': 'Freezing Rain',\n",
        "        'PPL': 'Ice Pellets',\n",
        "        'RA': 'Rain',\n",
        "        'SN': 'Snow',\n",
        "        'ZR': 'Freezing Rain',\n",
        "        'PL': 'Ice Pellets',\n",
        "        'UP': 'Unknown Precip',\n",
        "        'None': 'No Precip',\n",
        "        'NoForecast': 'No Forecast'\n",
        "    }\n",
        "\n",
        "    forecast_order = ['PRA', 'PSN', 'PZR', 'PPL']\n",
        "    obs_order = ['RA', 'SN', 'ZR', 'PL', 'UP']\n",
        "    forecast_label_order = [phenomena_label_map[k] for k in forecast_order]\n",
        "    obs_label_order = [phenomena_label_map[k] for k in obs_order]\n",
        "\n",
        "    # ---- FILTER FOR PRECIPITATION ----\n",
        "    if precip_only:\n",
        "        filtered_df = df[df[obs_cols].any(axis=1)]\n",
        "    else:\n",
        "        filtered_df = df\n",
        "\n",
        "    # ---- OBSERVATION LABELS ----\n",
        "    obs_array = filtered_df[obs_cols].values.astype(bool)\n",
        "    first_true_idx = obs_array.argmax(axis=1)\n",
        "    has_true = obs_array.any(axis=1)\n",
        "    obs_types = np.array(obs_cols)[first_true_idx]\n",
        "    obs_types[~has_true] = \"None\"\n",
        "    keep_mask = np.isin(obs_types, obs_order)\n",
        "    filtered_df = filtered_df.iloc[keep_mask].reset_index(drop=True)\n",
        "    obs_types = obs_types[keep_mask]\n",
        "\n",
        "    # ---- LEFT: VECTORIZED CONTINGENCY TABLE FOR ALL FCSTS > threshold, REMOVED NO FORECAST ----\n",
        "    fcst_probs = filtered_df[forecast_cols].values\n",
        "    above_thresh = fcst_probs > threshold\n",
        "\n",
        "    obs_types_repeated = np.repeat(obs_types, above_thresh.shape[1])\n",
        "    forecast_types_tiled = np.tile(np.array(forecast_cols), above_thresh.shape[0])\n",
        "    hits_mask = above_thresh.flatten()\n",
        "\n",
        "    df_hits = pd.DataFrame({\n",
        "        \"Forecast\": forecast_types_tiled[hits_mask],\n",
        "        \"Observation\": obs_types_repeated[hits_mask]\n",
        "    })\n",
        "\n",
        "    df_all = df_hits  # Only hits, no \"NoForecast\"\n",
        "    ct = pd.crosstab(df_all[\"Forecast\"], df_all[\"Observation\"])\n",
        "    ct = ct.reindex(index=forecast_order, columns=obs_order, fill_value=0)\n",
        "    ct_pct = ct / ct.values.sum() * 100\n",
        "    ct_pct.index = [phenomena_label_map[idx] for idx in ct_pct.index]\n",
        "    ct_pct.columns = [phenomena_label_map.get(col, col) for col in ct_pct.columns]\n",
        "    ct_pct = ct_pct.reindex(index=forecast_label_order, columns=obs_label_order, fill_value=0)\n",
        "    annotations = ct_pct.round(1).astype(str) + '%'\n",
        "    left_total = ct_pct.values.sum()\n",
        "\n",
        "    # ---- TOP RIGHT: DOMINANT FORECAST BY OBSERVED TYPE (COLUMN SUMS 100%) ----\n",
        "    dominant_per_obs = pd.DataFrame(0, index=forecast_order, columns=obs_order, dtype=float)\n",
        "    case_count_per_cell = pd.DataFrame(0, index=forecast_order, columns=obs_order, dtype=int)\n",
        "    n_obs_type = pd.Series(0, index=obs_order)\n",
        "\n",
        "    for j, o_col in enumerate(obs_order):\n",
        "        mask = (obs_types == o_col)\n",
        "        n_obs_type[o_col] = mask.sum()\n",
        "        if n_obs_type[o_col] == 0:\n",
        "            continue\n",
        "        fcst_probs_slice = filtered_df[forecast_cols].values[mask]\n",
        "        dom_fcst = np.where(\n",
        "            (fcst_probs_slice.max(axis=1) > threshold),\n",
        "            np.array(forecast_cols)[fcst_probs_slice.argmax(axis=1)],\n",
        "            \"NoForecast\"\n",
        "        )\n",
        "        for i, f_col in enumerate(forecast_order):\n",
        "            count = (dom_fcst == f_col).sum()\n",
        "            dominant_per_obs.loc[f_col, o_col] = 100 * count / n_obs_type[o_col] if n_obs_type[o_col] else 0\n",
        "            case_count_per_cell.loc[f_col, o_col] = count\n",
        "\n",
        "    dominant_per_obs.index = [phenomena_label_map[idx] for idx in dominant_per_obs.index]\n",
        "    dominant_per_obs.columns = [phenomena_label_map.get(col, col) for col in dominant_per_obs.columns]\n",
        "    dominant_per_obs = dominant_per_obs.reindex(index=forecast_label_order, columns=obs_label_order, fill_value=0)\n",
        "    dom_per_obs_annotations = dominant_per_obs.round(1).astype(str) + '%'\n",
        "\n",
        "    # ---- BOTTOM LEFT: NORMALIZED CONDITIONAL TABLE (row sums to 100%) ----\n",
        "    cond_table = pd.DataFrame(0, index=forecast_order, columns=obs_order, dtype=float)\n",
        "    for i, f_col in enumerate(forecast_cols):\n",
        "        mask = filtered_df[f_col] > threshold\n",
        "        obs_for_fcst = obs_types[mask.values]\n",
        "        obs_for_fcst = obs_for_fcst[np.isin(obs_for_fcst, obs_order)]\n",
        "        if len(obs_for_fcst) > 0:\n",
        "            counts = pd.Series(obs_for_fcst).value_counts()\n",
        "            for o_col in counts.index:\n",
        "                cond_table.loc[f_col, o_col] = counts[o_col]\n",
        "            cond_table.loc[f_col] = cond_table.loc[f_col] / cond_table.loc[f_col].sum() * 100\n",
        "    cond_table.index = [phenomena_label_map[idx] for idx in cond_table.index]\n",
        "    cond_table.columns = [phenomena_label_map.get(col, col) for col in cond_table.columns]\n",
        "    cond_table = cond_table.reindex(index=forecast_label_order, columns=obs_label_order, fill_value=0)\n",
        "    cond_annotations = cond_table.round(1).astype(str) + '%'\n",
        "\n",
        "    # ---- BOTTOM RIGHT: INVERSE CONDITIONAL TABLE (col sums to 100%) ----\n",
        "    inv_cond_table = pd.DataFrame(0, index=forecast_order, columns=obs_order, dtype=float)\n",
        "    for j, o_col in enumerate(obs_cols):\n",
        "        mask = filtered_df[o_col].astype(bool).values if o_col in filtered_df else (obs_types == o_col)\n",
        "        if mask.sum() > 0:\n",
        "            for i, f_col in enumerate(forecast_cols):\n",
        "                fcst_hit = (filtered_df[f_col][mask] > threshold).sum()\n",
        "                inv_cond_table.loc[f_col, o_col] = fcst_hit\n",
        "            inv_cond_table[o_col] = inv_cond_table[o_col] / inv_cond_table[o_col].sum() * 100 if inv_cond_table[o_col].sum() > 0 else 0\n",
        "    inv_cond_table.index = [phenomena_label_map[idx] for idx in inv_cond_table.index]\n",
        "    inv_cond_table.columns = [phenomena_label_map.get(col, col) for col in inv_cond_table.columns]\n",
        "    inv_cond_table = inv_cond_table.reindex(index=forecast_label_order, columns=obs_label_order, fill_value=0)\n",
        "    inv_cond_annotations = inv_cond_table.round(1).astype(str) + '%'\n",
        "\n",
        "    # ---- PLOT 2x2 ----\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(18, 12), sharey='row')\n",
        "    sns.heatmap(ct_pct, annot=annotations, fmt='', cmap='Blues', cbar_kws={'label': '% of total'}, ax=axes[0,0])\n",
        "    axes[0,0].set_xlabel('Observation Type')\n",
        "    axes[0,0].set_ylabel('Forecast Type')\n",
        "    axes[0,0].set_title(\n",
        "        f'Any Forecast > {int(threshold*100)}%' +\n",
        "        (f'\\n(Precipitating Cases Only)' if precip_only else '') +\n",
        "        f'\\nTotal: {left_total:.1f}%'\n",
        "    )\n",
        "    axes[0,0].tick_params(axis='y', labelrotation=0)\n",
        "\n",
        "    sns.heatmap(dominant_per_obs, annot=dom_per_obs_annotations, fmt='', cmap='Blues', cbar_kws={'label': '% dominant forecast by obs'}, ax=axes[0,1])\n",
        "    axes[0,1].set_xlabel('Observation Type')\n",
        "    axes[0,1].set_ylabel('Forecast Type')\n",
        "    axes[0,1].set_title('Dominant Forecast Given Obs Type\\n(Column sums = 100%)')\n",
        "    axes[0,1].tick_params(axis='y', labelrotation=0)\n",
        "\n",
        "    sns.heatmap(cond_table, annot=cond_annotations, fmt='', cmap='Blues', cbar_kws={'label': '% given forecast'}, ax=axes[1,0])\n",
        "    axes[1,0].set_xlabel('Observation Type')\n",
        "    axes[1,0].set_ylabel('Forecast Type')\n",
        "    axes[1,0].set_title('P(Obs | Forecast Type > 15%)\\n(Row sums = 100%)')\n",
        "    axes[1,0].tick_params(axis='y', labelrotation=0)\n",
        "\n",
        "    sns.heatmap(inv_cond_table, annot=inv_cond_annotations, fmt='', cmap='Blues', cbar_kws={'label': '% given obs'}, ax=axes[1,1])\n",
        "    axes[1,1].set_xlabel('Observation Type')\n",
        "    axes[1,1].set_ylabel('Forecast Type')\n",
        "    axes[1,1].set_title('P(Forecast Type > 15% | Obs)\\n(Column sums = 100%)')\n",
        "    axes[1,1].tick_params(axis='y', labelrotation=0)\n",
        "\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df_all)\n",
        "\n",
        "    plot_title = (\n",
        "        f\"PoT Forecast by Observed Type\\n\"\n",
        "        f\"{start_date} to {end_date}\\nCWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Used Cases: {case_count}\\n\"\n",
        "    )\n",
        "\n",
        "    fig.suptitle(plot_title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "median_forecast_prob_output = Output()\n",
        "\n",
        "with median_forecast_prob_output:\n",
        "    plot_median_forecast_prob_percent = True\n",
        "\n",
        "    category_names = ['Rain', 'Snow', 'Freezing Rain', 'Ice Pellets']\n",
        "    forecast_keys = ['PRA', 'PSN', 'PZR', 'PPL']\n",
        "    observed_names = ['Rain', 'Snow', 'Freezing Rain', 'Ice Pellets', 'Unknown']\n",
        "    observed_keys = ['RA', 'SN', 'ZR', 'PL', 'UP']\n",
        "\n",
        "    df_ct = df.copy()\n",
        "\n",
        "    if plot_median_forecast_prob_percent:\n",
        "        n_forecast = len(forecast_keys)\n",
        "        n_obs = len(observed_keys)\n",
        "        matrix_median = np.full((n_forecast, n_obs), np.nan)\n",
        "        matrix_p25 = np.full((n_forecast, n_obs), np.nan)\n",
        "        matrix_p75 = np.full((n_forecast, n_obs), np.nan)\n",
        "        matrix_count = np.full((n_forecast, n_obs), np.nan)\n",
        "        for obs_idx, obs_key in enumerate(observed_keys):\n",
        "            mask_obs = df_ct[obs_key] > 0.15\n",
        "            df_obs = df_ct[mask_obs]\n",
        "            for fcst_idx, fcst_key in enumerate(forecast_keys):\n",
        "                mask_fcst = df_obs[fcst_key] > 0\n",
        "                values = df_obs.loc[mask_fcst, fcst_key]\n",
        "                if len(values) > 0:\n",
        "                    matrix_median[fcst_idx, obs_idx] = np.median(values) * 100\n",
        "                    matrix_p25[fcst_idx, obs_idx] = np.percentile(values, 25) * 100\n",
        "                    matrix_p75[fcst_idx, obs_idx] = np.percentile(values, 75) * 100\n",
        "                    matrix_count[fcst_idx, obs_idx] = len(values)\n",
        "                else:\n",
        "                    matrix_median[fcst_idx, obs_idx] = np.nan\n",
        "                    matrix_p25[fcst_idx, obs_idx] = np.nan\n",
        "                    matrix_p75[fcst_idx, obs_idx] = np.nan\n",
        "                    matrix_count[fcst_idx, obs_idx] = 0\n",
        "        fmt = \".1f\"\n",
        "        cbar_label = \"Median Forecast Probability (%)\"\n",
        "        plot_title = 'Forecast Probability by Observed Type\\n(Median [25th–75th Percentile], case count)'\n",
        "        vmin, vmax = 0, 100\n",
        "        percent_sign = True\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    row_labels = [f\"Forecast {n}\" for n in category_names]\n",
        "    contingency_df = pd.DataFrame(\n",
        "        matrix_median,\n",
        "        index=row_labels,\n",
        "        columns=[f\"Observed {n}\" for n in observed_names]\n",
        "    )\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    sns.heatmap(\n",
        "        contingency_df,\n",
        "        annot=False, fmt=fmt, cmap=\"Blues\", cbar=True,\n",
        "        ax=ax, cbar_kws={'label': cbar_label},\n",
        "        vmin=vmin, vmax=vmax\n",
        "    )\n",
        "\n",
        "    # Annotate: median bold, percentiles smaller, gray, not bold, count to the right (vertical)\n",
        "    for i in range(matrix_median.shape[0]):\n",
        "        for j in range(matrix_median.shape[1]):\n",
        "            median_val = matrix_median[i, j]\n",
        "            p25_val = matrix_p25[i, j]\n",
        "            p75_val = matrix_p75[i, j]\n",
        "            count_val = int(matrix_count[i, j]) if not np.isnan(matrix_count[i, j]) else 0\n",
        "            if not np.isnan(median_val):\n",
        "                ax.text(\n",
        "                    j + 0.5, i + 0.32, f\"{p75_val:.1f}%\",\n",
        "                    ha='center', va='bottom', fontsize=10, color='gray', fontweight='normal'\n",
        "                )\n",
        "                ax.text(\n",
        "                    j + 0.5, i + 0.5, f\"{median_val:.1f}%\",\n",
        "                    ha='center', va='center', fontsize=13, color='black', fontweight='bold'\n",
        "                )\n",
        "                ax.text(\n",
        "                    j + 0.5, i + 0.68, f\"{p25_val:.1f}%\",\n",
        "                    ha='center', va='top', fontsize=10, color='gray', fontweight='normal'\n",
        "                )\n",
        "                ax.text(\n",
        "                    j + 0.85, i + 0.5, f\"({count_val})\",\n",
        "                    ha='center', va='center', fontsize=10, color='gray', fontweight='normal', rotation=-90\n",
        "                )\n",
        "\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df)\n",
        "\n",
        "    plot_title = (\n",
        "        f\"25th/Median/75th Percentile PoT Forecasts (and Case Counts) by Observed Type\\n\"\n",
        "        f\"{start_date} to {end_date}\\nCWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "\n",
        "    ax.set_title(plot_title)\n",
        "    ax.set_xlabel(\"Observed Type\")\n",
        "    ax.set_ylabel(\"Forecast Type\")\n",
        "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "prob_type_distributions_output = Output()\n",
        "\n",
        "with prob_type_distributions_output:\n",
        "    forecast_keys = ['PRA', 'PSN', 'PZR', 'PPL']\n",
        "    forecast_names = ['Rain', 'Snow', 'Freezing Rain', 'Ice Pellets']\n",
        "    forecast_colors = {\n",
        "        'PRA': '#228B22',    # Green\n",
        "        'PSN': '#1E3A8A',    # Blue\n",
        "        'PZR': '#008B8B',    # Aqua\n",
        "        'PPL': '#800080',    # Purple\n",
        "    }\n",
        "    hatch_style = '////'\n",
        "\n",
        "    observed_keys = ['RA', 'SN', 'ZR', 'PL', 'UP']\n",
        "    panel_titles = [\n",
        "        'Rain Observed', 'Snow Observed',\n",
        "        'Freezing Rain Observed', 'Ice Pellets Observed', 'Unknown Precip Observed'\n",
        "    ]\n",
        "    panel_to_grid = [(0,0), (0,1), (1,0), (1,1), (1,2)]\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 10))\n",
        "    gs = gridspec.GridSpec(2, 3, height_ratios=[1,1])\n",
        "\n",
        "    axes = []\n",
        "    for idx, (row, col) in enumerate(panel_to_grid):\n",
        "        ax = plt.subplot(gs[row, col])\n",
        "        axes.append(ax)\n",
        "\n",
        "    for i, (obs_key, panel_title) in enumerate(zip(observed_keys, panel_titles)):\n",
        "        ax = axes[i]\n",
        "        data_true = [df.loc[df[obs_key]==True, key] for key in forecast_keys]\n",
        "        data_false = [df.loc[df[obs_key]==False, key] for key in forecast_keys]\n",
        "        for j, key in enumerate(forecast_keys):\n",
        "            # True, solid\n",
        "            ax.boxplot(\n",
        "                [data_true[j]],\n",
        "                positions=[j-0.18],\n",
        "                vert=False,\n",
        "                widths=0.32,\n",
        "                patch_artist=True,\n",
        "                boxprops=dict(facecolor=forecast_colors[key], color=forecast_colors[key], linewidth=2),\n",
        "                medianprops=dict(color='black', linewidth=2),\n",
        "                showfliers=False\n",
        "            )\n",
        "            # False, hatched\n",
        "            ax.boxplot(\n",
        "                [data_false[j]],\n",
        "                positions=[j+0.18],\n",
        "                vert=False,\n",
        "                widths=0.32,\n",
        "                patch_artist=True,\n",
        "                boxprops=dict(facecolor='white', color=forecast_colors[key], linewidth=2, hatch=hatch_style),\n",
        "                medianprops=dict(color=forecast_colors[key], linewidth=2),\n",
        "                showfliers=False\n",
        "            )\n",
        "        ax.set_yticks(range(len(forecast_keys)))\n",
        "        ax.set_yticklabels(forecast_names)\n",
        "        ax.set_title(panel_title)\n",
        "        ax.set_xlabel('Forecast Probability')\n",
        "        if i in [0, 2]:  # First column of each row\n",
        "            ax.set_ylabel('Forecast Category')\n",
        "        else:\n",
        "            ax.set_ylabel(\"\")\n",
        "        ax.grid(axis='x', linestyle=':', alpha=0.7)\n",
        "        ax.axvline(0.15, color='gray', linestyle='--', linewidth=2, alpha=0.7)\n",
        "\n",
        "    # Legend in the upper right empty panel (gs[0,2])\n",
        "    legend_ax = plt.subplot(gs[0,2])\n",
        "    legend_ax.axis('off')\n",
        "    legend_elements = [\n",
        "        Patch(facecolor=forecast_colors['PRA'], edgecolor=forecast_colors['PRA'], label='Solid: Obs True'),\n",
        "        Patch(facecolor='white', edgecolor='black', hatch=hatch_style, label='Hatched: Obs False'),\n",
        "        Patch(facecolor=forecast_colors['PRA'], edgecolor=forecast_colors['PRA'], label='PRA (Rain)'),\n",
        "        Patch(facecolor=forecast_colors['PSN'], edgecolor=forecast_colors['PSN'], label='PSN (Snow)'),\n",
        "        Patch(facecolor=forecast_colors['PZR'], edgecolor=forecast_colors['PZR'], label='PZR (Freezing Rain)'),\n",
        "        Patch(facecolor=forecast_colors['PPL'], edgecolor=forecast_colors['PPL'], label='PPL (Ice Pellets)'),\n",
        "    ]\n",
        "    legend = legend_ax.legend(\n",
        "        handles=legend_elements,\n",
        "        loc='center',\n",
        "        fontsize=13,\n",
        "        frameon=True,\n",
        "        framealpha=0.95\n",
        "    )\n",
        "\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df)\n",
        "\n",
        "    plot_title = (\n",
        "        f\"Probability of Type Distributions by Observed Type\\n\"\n",
        "        f\"{start_date} to {end_date}\\nCWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "\n",
        "    fig.suptitle(plot_title)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "snow_level_by_obs_type_output = Output()\n",
        "\n",
        "with snow_level_by_obs_type_output:\n",
        "    # Set the forecast hour you want, or None for all:\n",
        "    fhr_value = None  # Example: 3, 6, 9, etc. Set to None for all\n",
        "\n",
        "    # Observed types and colors (flipped vertical order)\n",
        "    obs_keys = ['UP', 'PL', 'ZR', 'SN', 'RA']\n",
        "    obs_labels = ['Unknown', 'Ice Pellets', 'Freezing Rain', 'Snow', 'Rain']\n",
        "    obs_colors = ['#C62828', '#800080', '#008B8B', '#1E3A8A', '#228B22']\n",
        "\n",
        "    data = []\n",
        "    for obs_key in obs_keys:\n",
        "        # First, get the right subset by fhr MultiIndex level\n",
        "        if fhr_value is not None:\n",
        "            try:\n",
        "                subset = df.xs(fhr_value, level='fhr')\n",
        "            except KeyError:\n",
        "                subset = df.iloc[0:0]  # empty frame\n",
        "        else:\n",
        "            subset = df\n",
        "        subset = subset[subset[obs_key] == True]\n",
        "        data.append(subset['snowlvl_agl'].dropna())\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(11, 5))\n",
        "\n",
        "    # Use tick_labels instead of labels (for matplotlib >=3.9)\n",
        "    box = ax.boxplot(\n",
        "        data,\n",
        "        vert=False,\n",
        "        patch_artist=True,\n",
        "        widths=0.6,\n",
        "        tick_labels=obs_labels,\n",
        "        showfliers=False,\n",
        "        flierprops=dict(marker='o', markerfacecolor='gray', markeredgecolor='black', alpha=0.6, markersize=5)\n",
        "    )\n",
        "\n",
        "    for patch, color in zip(box['boxes'], obs_colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_edgecolor(color)\n",
        "    for median in box['medians']:\n",
        "        median.set_color('orange')\n",
        "        median.set_linewidth(2)\n",
        "\n",
        "    ax.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.8)\n",
        "    ax.axvline(800, color='gray', linestyle='--', linewidth=2, alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel(\"Snow Level AGL (ft)\", fontsize=13)\n",
        "    ax.set_yticklabels(obs_labels, fontsize=12)\n",
        "\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df)\n",
        "\n",
        "    plot_title = (\n",
        "        f\"Snow Level (ft AGL) Distributions by Observed Type\\n\"\n",
        "        f\"{start_date} to {end_date}\\nCWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "\n",
        "    plt.suptitle(plot_title)\n",
        "\n",
        "    ax.grid(axis='x', linestyle=':', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "snowlvl_vs_pot_discrimination_output = Output()\n",
        "\n",
        "with snowlvl_vs_pot_discrimination_output:\n",
        "    # Step 1: Define the thresholds and split the data for the first row\n",
        "    threshold_high = 800\n",
        "    threshold_low = 0\n",
        "\n",
        "    df_high_snowlvl = df[df['snowlvl_agl'] > threshold_high]  # Left panel: snowlvl_agl > 800\n",
        "    df_mid_snowlvl = df[(df['snowlvl_agl'] > threshold_low) & (df['snowlvl_agl'] <= threshold_high)]  # Middle panel: 0 < snowlvl_agl <= 800\n",
        "    df_low_snowlvl = df[df['snowlvl_agl'] <= threshold_low]  # Right panel: snowlvl_agl <= 0\n",
        "\n",
        "    # Step 2: Define the conditions for the second row\n",
        "    df_pra_gt_psn = df[df['PRA'] > df['PSN']]  # Left panel: PRA > PSN\n",
        "    df_pra_within_psn = df[abs(df['PRA'] - df['PSN']) <= 0.15]  # Middle panel: PRA and PSN within ±15%\n",
        "    df_psn_gt_pra = df[df['PSN'] > df['PRA']]  # Right panel: PSN > PRA\n",
        "\n",
        "    # Step 3: Count the frequencies of weather types for all six panels\n",
        "    weather_types = ['RA', 'SN', 'ZR', 'PL', 'UP']\n",
        "    colors = ['green', 'blue', 'teal', 'purple', 'red']  # Colors for RA, SN, ZR, PL, UP\n",
        "\n",
        "    # Compute raw counts\n",
        "    freq_high_snowlvl = df_high_snowlvl[weather_types].sum()\n",
        "    freq_mid_snowlvl = df_mid_snowlvl[weather_types].sum()\n",
        "    freq_low_snowlvl = df_low_snowlvl[weather_types].sum()\n",
        "\n",
        "    freq_pra_gt_psn = df_pra_gt_psn[weather_types].sum()\n",
        "    freq_pra_within_psn = df_pra_within_psn[weather_types].sum()\n",
        "    freq_psn_gt_pra = df_psn_gt_pra[weather_types].sum()\n",
        "\n",
        "    # Helper function to compute percent frequencies\n",
        "    def compute_percent_freq(raw_counts):\n",
        "        total = raw_counts.sum()\n",
        "        return (raw_counts / total) * 100 if total > 0 else raw_counts\n",
        "\n",
        "    # Convert raw counts to percentages\n",
        "    percent_high_snowlvl = compute_percent_freq(freq_high_snowlvl)\n",
        "    percent_mid_snowlvl = compute_percent_freq(freq_mid_snowlvl)\n",
        "    percent_low_snowlvl = compute_percent_freq(freq_low_snowlvl)\n",
        "\n",
        "    percent_pra_gt_psn = compute_percent_freq(freq_pra_gt_psn)\n",
        "    percent_pra_within_psn = compute_percent_freq(freq_pra_within_psn)\n",
        "    percent_psn_gt_pra = compute_percent_freq(freq_psn_gt_pra)\n",
        "\n",
        "    # Case counts for each plot\n",
        "    case_counts = {\n",
        "        'high_snowlvl': len(df_high_snowlvl),\n",
        "        'mid_snowlvl': len(df_mid_snowlvl),\n",
        "        'low_snowlvl': len(df_low_snowlvl),\n",
        "        'pra_gt_psn': len(df_pra_gt_psn),\n",
        "        'pra_within_psn': len(df_pra_within_psn),\n",
        "        'psn_gt_pra': len(df_psn_gt_pra),\n",
        "    }\n",
        "\n",
        "    # Total case count\n",
        "    total_cases = len(df)\n",
        "\n",
        "    # Step 4: Plot the 2x3 grid of histograms\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(14, 8), sharey=False)  # Allow independent y-axes for each plot\n",
        "\n",
        "    # Helper function to annotate bars with percentages and case count\n",
        "    def annotate_bars(ax, values, case_count, total_cases):\n",
        "        for i, value in enumerate(values):\n",
        "            ax.text(i, value + 1, f'{value:.3f}%', ha='center', fontsize=10)\n",
        "        case_percentage = (case_count / total_cases) * 100 if total_cases > 0 else 0\n",
        "        ax.text(\n",
        "            0.95, 0.95,\n",
        "            f\"Cases: {case_count}\\n({case_percentage:.1f}%)\",\n",
        "            ha='right', va='top', fontsize=10,\n",
        "            transform=ax.transAxes,\n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", edgecolor=\"black\")\n",
        "        )\n",
        "\n",
        "    # First Row\n",
        "    axes[0, 0].bar(weather_types, percent_high_snowlvl, color=colors)\n",
        "    annotate_bars(axes[0, 0], percent_high_snowlvl, case_counts['high_snowlvl'], total_cases)\n",
        "    axes[0, 0].set_ylim(0, percent_high_snowlvl.max() * 1.2)  # Add headspace\n",
        "    axes[0, 0].set_title('snowlvl_agl > 800', fontsize=14, weight='bold')\n",
        "    axes[0, 0].set_ylabel('Percent Frequency', fontsize=12)\n",
        "    axes[0, 0].yaxis.set_major_formatter(PercentFormatter())\n",
        "\n",
        "    axes[0, 1].bar(weather_types, percent_mid_snowlvl, color=colors)\n",
        "    annotate_bars(axes[0, 1], percent_mid_snowlvl, case_counts['mid_snowlvl'], total_cases)\n",
        "    axes[0, 1].set_ylim(0, percent_mid_snowlvl.max() * 1.2)  # Add headspace\n",
        "    axes[0, 1].set_title('0 < snowlvl_agl <= 800', fontsize=14, weight='bold')\n",
        "    axes[0, 1].yaxis.set_major_formatter(PercentFormatter())\n",
        "\n",
        "    axes[0, 2].bar(weather_types, percent_low_snowlvl, color=colors)\n",
        "    annotate_bars(axes[0, 2], percent_low_snowlvl, case_counts['low_snowlvl'], total_cases)\n",
        "    axes[0, 2].set_ylim(0, percent_low_snowlvl.max() * 1.2)  # Add headspace\n",
        "    axes[0, 2].set_title('snowlvl_agl <= 0', fontsize=14, weight='bold')\n",
        "    axes[0, 2].yaxis.set_major_formatter(PercentFormatter())\n",
        "\n",
        "    # Second Row\n",
        "    axes[1, 0].bar(weather_types, percent_pra_gt_psn, color=colors)\n",
        "    annotate_bars(axes[1, 0], percent_pra_gt_psn, case_counts['pra_gt_psn'], total_cases)\n",
        "    axes[1, 0].set_ylim(0, percent_pra_gt_psn.max() * 1.2)  # Add headspace\n",
        "    axes[1, 0].set_title('PRA > PSN', fontsize=14, weight='bold')\n",
        "    axes[1, 0].set_ylabel('Percent Frequency', fontsize=12)\n",
        "    axes[1, 0].yaxis.set_major_formatter(PercentFormatter())\n",
        "\n",
        "    axes[1, 1].bar(weather_types, percent_pra_within_psn, color=colors)\n",
        "    annotate_bars(axes[1, 1], percent_pra_within_psn, case_counts['pra_within_psn'], total_cases)\n",
        "    axes[1, 1].set_ylim(0, percent_pra_within_psn.max() * 1.2)  # Add headspace\n",
        "    axes[1, 1].set_title('PRA within ±15% of PSN', fontsize=14, weight='bold')\n",
        "    axes[1, 1].yaxis.set_major_formatter(PercentFormatter())\n",
        "\n",
        "    axes[1, 2].bar(weather_types, percent_psn_gt_pra, color=colors)\n",
        "    annotate_bars(axes[1, 2], percent_psn_gt_pra, case_counts['psn_gt_pra'], total_cases)\n",
        "    axes[1, 2].set_ylim(0, percent_psn_gt_pra.max() * 1.2)  # Add headspace\n",
        "    axes[1, 2].set_title('PSN > PRA', fontsize=14, weight='bold')\n",
        "    axes[1, 2].yaxis.set_major_formatter(PercentFormatter())\n",
        "\n",
        "    # Gather info for the title\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df)\n",
        "\n",
        "    plot_title = (\n",
        "        f\"Snow Level vs PoT Discrimination\\n\"\n",
        "        f\"{start_date} to {end_date}\\nCWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "\n",
        "    plt.suptitle(plot_title, fontsize=16)\n",
        "\n",
        "    # Adjust layout and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "pot_reliability_output = Output()\n",
        "\n",
        "with pot_reliability_output:\n",
        "    tw_up_limit = 36\n",
        "\n",
        "    pairs = [\n",
        "        ('PRA', 'RA'),\n",
        "        ('PSN', 'SN'),\n",
        "        ('PZR+PPL', 'ZR+PL+UP')\n",
        "    ]\n",
        "\n",
        "    # Create combined category (shared probabilities and observations)\n",
        "    df['PZR+PPL'] = (df['PZR'] + df['PPL'])  # SUM of PZR and PPL\n",
        "    df['ZR+PL+UP'] = df['ZR'] | df['PL'] | ((df['UP'] & (df['Tw'] <= tw_up_limit)))\n",
        "\n",
        "    total_stations = df.index.get_level_values('stid').nunique()\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "    for idx, (prob_col, obs_col) in enumerate(pairs):\n",
        "        probabilities = df[prob_col]\n",
        "        observations = df[obs_col]\n",
        "\n",
        "        prob_true, prob_pred = calibration_curve(observations, probabilities, n_bins=10, strategy='uniform')\n",
        "\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        ax.plot(prob_pred, prob_true, marker='o')\n",
        "        ax.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "\n",
        "        true_count = observations.sum()\n",
        "\n",
        "        if prob_col == 'PZR+PPL' and obs_col == 'ZR+PL+UP':\n",
        "            obs_col_mod = obs_col.replace(\"UP\", f\"(UP & Tw \\u2264 {tw_up_limit}°F)\")\n",
        "            ax.set_title(\n",
        "                f'Reliability Curve: {prob_col} vs {obs_col_mod}\\nTrue Count: {true_count}',\n",
        "                fontsize=10\n",
        "            )\n",
        "        else:\n",
        "            ax.set_title(f'Reliability Curve: {prob_col} vs {obs_col}\\nTrue Count: {true_count}', fontsize=10)\n",
        "\n",
        "        ax.set_xlabel('Predicted Probability')\n",
        "        ax.set_ylabel('Observed Frequency')\n",
        "        ax.grid(True)\n",
        "\n",
        "        sharpness_ax = ax.inset_axes([0.1, 0.8, 0.3, 0.15])\n",
        "        sharpness_ax.hist(probabilities * 100, bins=np.arange(0, 110, 10), color='blue', alpha=0.7, edgecolor='black')\n",
        "        sharpness_ax.set_title('Sharpness', fontsize=8)\n",
        "        sharpness_ax.set_xlabel('Forecast (%)', fontsize=8)\n",
        "        sharpness_ax.set_ylabel('Count', fontsize=8)\n",
        "        sharpness_ax.tick_params(axis='both', which='major', labelsize=6)\n",
        "        sharpness_ax.grid(True, linestyle='--', alpha=0.5)\n",
        "        sharpness_ax.set_yscale('log')\n",
        "\n",
        "        roc_ax = ax.inset_axes([0.7, 0.10, 0.25, 0.25])\n",
        "        fpr, tpr, _ = roc_curve(observations, probabilities)\n",
        "        auc_score = roc_auc_score(observations, probabilities)\n",
        "        roc_ax.plot(fpr, tpr, color='darkorange', lw=2, label='ROC')\n",
        "        roc_ax.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1)\n",
        "        roc_ax.set_title('ROC Curve', fontsize=8)\n",
        "        roc_ax.set_xlabel('FPR', fontsize=8)\n",
        "        roc_ax.set_ylabel('TPR', fontsize=8)\n",
        "        roc_ax.tick_params(axis='both', which='major', labelsize=6)\n",
        "        roc_ax.grid(True, linestyle='--', alpha=0.5)\n",
        "        roc_ax.text(0.6, 0.2, f'AUC: {auc_score:.2f}', fontsize=8, bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    unique_cwas = \", \".join(cwa_selection) if isinstance(cwa_selection, list) and cwa_selection else \"All CWAs\"\n",
        "    unique_fhrs = \", \".join([str(f) for f in fhr_selection]) if fhr_selection else \"All FHRs\"\n",
        "    case_count = len(df)\n",
        "\n",
        "    plot_title = (\n",
        "        f\"PoT Reliability Plots\\n\"\n",
        "        f\"{start_date} to {end_date}\\nCWAs: {unique_cwas} | FHRs: {unique_fhrs} | Total Cases: {case_count}\"\n",
        "    )\n",
        "\n",
        "    fig.suptitle(plot_title, fontsize=16, y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "# --- Display all tabs (update this section as you add tabs) ---\n",
        "tab_titles = [\n",
        "    \"Weather Combinations\",\n",
        "    \"Weather 2x2 Histogram\",\n",
        "    \"ZR vs UP Event Panels\",\n",
        "    \"Probability Histograms\",\n",
        "    \"Forecast/Obs Contingency\",\n",
        "    \"Median Forecast Probabilities\",\n",
        "    \"PoT Distributions by Obs Type\",\n",
        "    \"Snow Level by Obs Type\",\n",
        "    \"SnowLvl vs PoT Discrimination\",\n",
        "    \"PoT Reliability\"\n",
        "]\n",
        "\n",
        "tab_contents = [\n",
        "    combo_output,\n",
        "    hist2x2_output,\n",
        "    hist_panel_output,\n",
        "    prob_hist_output,\n",
        "    contingency_matrix_output,\n",
        "    median_forecast_prob_output,\n",
        "    prob_type_distributions_output,\n",
        "    snow_level_by_obs_type_output,\n",
        "    snowlvl_vs_pot_discrimination_output,\n",
        "    pot_reliability_output\n",
        "]\n",
        "\n",
        "tabs = Tab(children=tab_contents)\n",
        "\n",
        "for i, title in enumerate(tab_titles):\n",
        "    tabs.set_title(i, title)\n",
        "display(tabs)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XEtv9By8MZ6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}